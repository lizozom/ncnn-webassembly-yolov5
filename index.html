<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width" />
    <title>ncnn webassembly yolov5</title>
    <style>
        video {
/*             position: absolute; */
/*             visibility: hidden; */
        }
        canvas {
            border: 1px solid black;
        }
    </style>

</head>

<body>
    <div>
        <h1>ncnn webassembly yolov5</h1>
        <div>
            <button disabled id="switch-camera-btn" style="height:48px">Switch Camera</button>
        </div>
        <video id="video" style="display: none;" playsinline autoplay></video>

        
        <div style="padding-top: 1200px">
            <canvas id="canvas" width="640"></canvas>
        </div>
        <img class="dp-img" src="nondp.jpg" />
    </div>

    <script src="wasmFeatureDetect.js"></script>

    <script type='text/javascript'>
        const BASE_SIZE = 640;
        var Module = {};

        var has_simd;
        var has_threads;

        var wasmModuleLoaded = false;
        var wasmModuleLoadedCallbacks = [];


    async function getImageTensorFromPath(path, dims =  [1, 3, 224, 224]) {
        // 1. load the image  
        var image = await loadImageFromPath(path, dims[2], dims[3]);
        // 2. convert to tensor
        var imageTensor = imageDataToTensor(image, dims);
        // 3. return the tensor
        return imageTensor;
    }

    async function loadImageFromPath(path, width = 224, height = 224) {

        var canvas = document.getElementById('canvas');
        var ctx = canvas.getContext('2d');

        var imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        return imageData.data;

        // Use Jimp to load the image and resize it.
        // var imageData = await Jimp.default.read(path).then((imageBuffer) => {
        //     return imageBuffer.resize(width, height);
        // });

        // return imageData;
    }

    function imageDataToTensor(image, dims) {
        // 1. Get buffer data from image and create R, G, and B arrays.
        var imageBufferData = image;
        const [redArray, greenArray, blueArray] = new Array(new Array(), new Array(), new Array());

        // 2. Loop through the image buffer and extract the R, G, and B channels
        for (let i = 0; i < imageBufferData.length; i += 4) {
            redArray.push(imageBufferData[i]);
            greenArray.push(imageBufferData[i + 1]);
            blueArray.push(imageBufferData[i + 2]);
            // skip data[i + 3] to filter out the alpha channel
        }

        // 3. Concatenate RGB to transpose [224, 224, 3] -> [3, 224, 224] to a number array
        const transposedData = redArray.concat(greenArray).concat(blueArray);

        // 4. convert to float32
        let i, l = transposedData.length; // length, we need this for the loop
        // create the Float32Array size 3 * 224 * 224 for these dimensions output
        const float32Data = new Float32Array(dims[1] * dims[2] * dims[3]);
        for (i = 0; i < l; i++) {
            float32Data[i] = transposedData[i] / 255.0; // convert to float
        }
        // 5. create the tensor object from onnxruntime-web.
        // const inputTensor = new Tensor("float32", float32Data, dims);
        // return inputTensor;

        return float32Data;
    }




        Module.onRuntimeInitialized = function() {
            wasmModuleLoaded = true;
            for (var i = 0; i < wasmModuleLoadedCallbacks.length; i++) {
                wasmModuleLoadedCallbacks[i]();
            }
        }

        wasmFeatureDetect.simd().then(simdSupported => {
            has_simd = simdSupported;

            wasmFeatureDetect.threads().then(threadsSupported => {
                has_threads = threadsSupported;

                if (has_simd)
                {
                    if (has_threads)
                    {
                        yolov5_module_name = 'yolov5-simd-threads';
                    }
                    else
                    {
                        yolov5_module_name = 'yolov5-simd';
                    }
                }
                else
                {
                    if (has_threads)
                    {
                        yolov5_module_name = 'yolov5-threads';
                    }
                    else
                    {
                        yolov5_module_name = 'yolov5-basic';
                    }
                }

                console.log('load ' + yolov5_module_name);

                var yolov5wasm = yolov5_module_name + '.wasm';
                var yolov5js = yolov5_module_name + '.js';

                fetch(yolov5wasm)
                    .then(response => response.arrayBuffer())
                    .then(buffer => {
                        Module.wasmBinary = buffer;
                        var script = document.createElement('script');
                        script.src = yolov5js;
                        script.onload = function() {
                            console.log('Emscripten boilerplate loaded.');
                        }
                        document.body.appendChild(script);
                    });

            });
        });

        var shouldFaceUser = true;
        var stream = null;
        var w = 640;
        var h = 480;

        var dst = null;
        var resultarray = null;
        var resultbuffer = null;
        var img = null;
        window.addEventListener('DOMContentLoaded', function() {
            var isStreaming = false;
            switchcamerabtn = document.getElementById('switch-camera-btn');
            video = document.getElementById('video');
            img = document.getElementsByClassName('dp-img')[0];
            canvas = document.getElementById('canvas');
            ctx = canvas.getContext('2d');

            // Wait until the video stream canvas play
            video.addEventListener('canplay', function(e) {
                if (!isStreaming) {
                    // videoWidth isn't always set correctly in all browsers
                    if (video.videoWidth > 0) h = video.videoHeight / (video.videoWidth / w);
                    canvas.setAttribute('width', BASE_SIZE);
                    canvas.setAttribute('height', BASE_SIZE);
                    isStreaming = true;
                }
            }, false);

            // Wait for the video to start to play
            video.addEventListener('play', function() {
                //Setup image memory
                var id = ctx.getImageData(0, 0, canvas.width, canvas.height);
                var d = id.data;

                if (wasmModuleLoaded) {
                    mallocAndCallSFilter();
                } else {
                    wasmModuleLoadedCallbacks.push(mallocAndCallSFilter);
                }

                function mallocAndCallSFilter() {
                    if (dst != null)
                    {
                        _free(dst);
                        dst = null;
                    }

                    dst = _malloc(d.length);

                    //console.log("What " + d.length);

                    sFilter();
                }
            });

            // check whether we can use facingMode
            var supports = navigator.mediaDevices.getSupportedConstraints();
            if (supports['facingMode'] === true) {
                switchcamerabtn.disabled = false;
            }

            switchcamerabtn.addEventListener('click', function() {
                if (stream == null)
                    return

                stream.getTracks().forEach(t => {
                    t.stop();
                });

                shouldFaceUser = !shouldFaceUser;
                capture();
            });

            capture();
        });

        function capture() {
            var constraints = { audio: false, video: { width: 640, height: 480, facingMode: shouldFaceUser ? 'user' : 'environment' } };
            navigator.mediaDevices.getUserMedia(constraints)
                .then(function(mediaStream) {
                    var video = document.querySelector('video');
                    stream = mediaStream;
                    video.srcObject = mediaStream;
                    video.onloadedmetadata = function(e) {
                        video.play();
                    };
                })
                .catch(function(err) {
                    console.log(err.message);
                });
        }


        async function ncnn_yolov5() {
            // var canvas = document.getElementById('canvas');
            // var ctx = canvas.getContext('2d');

            // var imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            // var data = imageData.data;

            const data = await getImageTensorFromPath('http://localhost:3000/nondp.jpg', [1, 3, 640, 640])

            HEAPU8.set(data, dst);

            _yolov5_ncnn(dst, canvas.width, canvas.height);

            var result = HEAPU8.subarray(dst, dst + data.length);
            // imageData.data.set(result);
            // ctx.putImageData(imageData, 0, 0);
        }

        //Request Animation Frame function
        var sFilter = function() {
            if (video.paused || video.ended) return;
            const cont = img;
            const contW = img.width;
            const contH = img.height;

            var dheight, dwidth, dx, dy, scale = undefined;

            ctx.fillRect(0, 0, BASE_SIZE, BASE_SIZE);
            if (contW > contH) {
                dwidth = BASE_SIZE;
                scale = contW/BASE_SIZE;
                dheight = contH / scale;
                dx = 0;
                dy = (BASE_SIZE - dheight) / 2;
            } else {
                dheight = BASE_SIZE;
                scale = contH/BASE_SIZE;
                dwidth = contW / scale;
                dx = (BASE_SIZE - dwidth) / 2;
                dy = 0;
            }

            ctx.drawImage(cont, 0, 0, contW, contH, dx, dy, dwidth, dheight);

            ncnn_yolov5();

            // window.requestAnimationFrame(sFilter);
        }

    </script>

</body>

</html>
